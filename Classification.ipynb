{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val rawData = sc.textFile(\"stumbleupon/train_noheader.tsv\")\n",
    "val records = rawData.map(line => line.split(\"\\t\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7395\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.mllib.regression.LabeledPoint\n",
    "import org.apache.spark.mllib.linalg.Vectors\n",
    "\n",
    "val data = records.map { r => \n",
    "    val trimmed = r.map(_.replaceAll(\"\\\"\", \"\"))\n",
    "    val label = trimmed(r.size - 1).toInt\n",
    "    val features = trimmed.slice(4, r.size - 1).map(d => if (d == \"?\") 0.0 else d.toDouble)\n",
    "    LabeledPoint(label, Vectors.dense(features))\n",
    "}\n",
    "data.cache\n",
    "val numData = data.count\n",
    "println(numData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//Data for Naive Bayes, with all the negative values changed to 0.0\n",
    "val nbData = records.map { r => \n",
    "    val trimmed = r.map(_.replaceAll(\"\\\"\", \"\"))\n",
    "    val label = trimmed(r.size - 1).toInt\n",
    "    val features = trimmed.slice(4, r.size - 1).map(d => if (d == \"?\") 0.0 else d.toDouble).map(d => if (d < 0) 0.0 else d)\n",
    "    LabeledPoint(label, Vectors.dense(features))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.classification.LogisticRegressionWithSGD\n",
    "import org.apache.spark.mllib.classification.SVMWithSGD\n",
    "import org.apache.spark.mllib.classification.NaiveBayes\n",
    "import org.apache.spark.mllib.tree.DecisionTree\n",
    "import org.apache.spark.mllib.tree.configuration.Algo\n",
    "import org.apache.spark.mllib.tree.impurity.Entropy\n",
    "\n",
    "val numIterations = 10\n",
    "val maxTreeDepth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//Logistic Regression model Training\n",
    "val lrModel = LogisticRegressionWithSGD.train(data, numIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//Support Vector Machine model Training\n",
    "val svmModel = SVMWithSGD.train(data, numIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//Naive Bayes model Training\n",
    "val nbModel = NaiveBayes.train(nbData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//Decision Tree model Training\n",
    "val dtModel = DecisionTree.train(data, Algo.Classification, Entropy, maxTreeDepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1.0\n",
      "True Label: 0.0\n"
     ]
    }
   ],
   "source": [
    "//Generating predictions\n",
    "val dataPoint = data.first\n",
    "val prediction = lrModel.predict(dataPoint.features)\n",
    "println(\"Prediction: \" + prediction)\n",
    "val trueLabel = dataPoint.label\n",
    "println(\"True Label: \" + trueLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0,1.0,1.0,1.0,1.0\n"
     ]
    }
   ],
   "source": [
    "//Predictions in bulk\n",
    "val predictions = lrModel.predict(data.map(lp => lp.features))\n",
    "println(predictions.take(5).mkString(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5146720757268425\n"
     ]
    }
   ],
   "source": [
    "//Evaluation\n",
    "val lrTotalCorrect = data.map{ point => \n",
    "    if(lrModel.predict(point.features) == point.label) 1 else 0\n",
    "}.sum\n",
    "\n",
    "val lrAccuracy = lrTotalCorrect / numData\n",
    "println(\"Logistic Regression Accuracy: \" + lrAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5146720757268425\n",
      "Naive Bayes Accuracy: 0.5803921568627451\n",
      "Decision Tree Accuracy: 0.6482758620689655\n"
     ]
    }
   ],
   "source": [
    "val svmTotalCorrect = data.map{ point => \n",
    "    if(svmModel.predict(point.features) == point.label) 1 else 0\n",
    "}.sum\n",
    "\n",
    "val nbTotalCorrect = nbData.map{ point =>\n",
    "    if(nbModel.predict(point.features) == point.label) 1 else 0\n",
    "}.sum\n",
    "val dtTotalCorrect = data.map{ point =>\n",
    "    val score = dtModel.predict(point.features)\n",
    "    val predicted = if(score > 0.5) 1 else 0\n",
    "    if(predicted == point.label) 1 else 0\n",
    "}.sum\n",
    "\n",
    "val svmAccuracy = svmTotalCorrect / numData\n",
    "println(\"SVM Accuracy: \" + svmAccuracy)\n",
    "val nbAccuracy = nbTotalCorrect / numData\n",
    "println(\"Naive Bayes Accuracy: \" + nbAccuracy)\n",
    "val dtAccuracy = dtTotalCorrect / numData\n",
    "println(\"Decision Tree Accuracy: \" + dtAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionModel, Area under PR: 75.6759%, Area under ROC: 50.1418%\n",
      "SVMModel, Area under PR: 75.6759%, Area under ROC: 50.1418%\n",
      "NaiveBayesModel, Area under PR: 68.0851%, Area under ROC: 58.3559%\n",
      "DecisionTreeModel, Area under PR: 74.3081%, Area under ROC: 64.8837%\n"
     ]
    }
   ],
   "source": [
    "//Metrics\n",
    "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "val metrics = Seq(lrModel, svmModel).map{ model => \n",
    "    val scoreAndLabels = data.map{ point =>\n",
    "        (model.predict(point.features), point.label)\n",
    "    }\n",
    "    val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n",
    "    (model.getClass.getSimpleName, metrics.areaUnderPR, metrics.areaUnderROC)\n",
    "}\n",
    "\n",
    "val nbMetrics = Seq(nbModel).map{ model =>\n",
    "    val scoreAndLabels = nbData.map{ point =>\n",
    "        val score = model.predict(point.features)\n",
    "        (if(score > 0.5) 1.0 else 0.0, point.label)\n",
    "    }\n",
    "    val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n",
    "    (model.getClass.getSimpleName, metrics.areaUnderPR, metrics.areaUnderROC)\n",
    "}\n",
    "\n",
    "val dtMetrics = Seq(dtModel).map{ model =>\n",
    "    val scoreAndLabels = data.map{ point =>\n",
    "        val score = model.predict(point.features)\n",
    "        (if(score>0.5)1.0 else 0.0, point.label)\n",
    "    }\n",
    "    val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n",
    "    (model.getClass.getSimpleName, metrics.areaUnderPR, metrics.areaUnderROC)\n",
    "}\n",
    "\n",
    "val allMetrics = metrics ++ nbMetrics ++ dtMetrics\n",
    "allMetrics.foreach{ case (m, pr, roc) =>\n",
    "    println(f\"$m, Area under PR: ${pr * 100.0}%2.4f%%, Area under ROC: ${roc * 100.0}%2.4f%%\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
